{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 2 script.\n",
    "from __future__ import division\n",
    "\n",
    "# External library.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_filter(data, thresh=80, value='zero'):\n",
    "    \"\"\"\n",
    "    Purpose\n",
    "    -------\n",
    "    1. Drop columns with all the values as NaNs.\n",
    "    2. Drop columns with NaNs over a certian limit.\n",
    "    3. Replace NaNs with a value.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    data: Dataframe.\n",
    "    thresh: Threshold for non-NaN values; default is 80%.\n",
    "    value: Value to replace NaN with; default is zero.\n",
    "           Options: 'zero', 'mean', 'median'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A modified Pandas dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = data.dropna(axis='columns', how='all')\n",
    "    threshold = int((data.shape[0] * thresh) / 100)\n",
    "    data = data.dropna(axis='columns', thresh=thresh)\n",
    "    if value == 'zero':\n",
    "        data = data.apply(lambda x: x.fillna(0)) \n",
    "    elif value == 'mean':\n",
    "        data = data.apply(lambda x: x.fillna(x.mean()))\n",
    "    elif value == 'median':\n",
    "        data = data.apply(lambda x: x.fillna(x.median()))\n",
    "  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_thresh(data, thresh=0.0):\n",
    "    \"\"\"\n",
    "    Purpose\n",
    "    -------\n",
    "    1. Select columns with variace greater than a specified threshold.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    data: Dataframe with column values in float64 and devoid of missing values.\n",
    "    thresh: Variace threshold. Default is 0.0 (float)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A modified Pandas dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    selector = VarianceThreshold(threshold=thresh)\n",
    "    selector.fit(data)\n",
    "    idx = np.where(selector.variances_ > thresh)[0]\n",
    "    cols = data.columns[idx]\n",
    "    df = data[cols]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_mm(data, feat_range=(0,1)):\n",
    "    \"\"\"\n",
    "    Purpose\n",
    "    -------\n",
    "    Transforms features by scaling each feature to a given range using  Scikit-learn MinMaxScaler.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    data: Pandas dataframe.\n",
    "    feat_range: Scale range in a tuple. Default is (0,1)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Transformed Pandas dataframe.\n",
    "    \n",
    "    \"\"\"\n",
    "    cols = list(data.columns)\n",
    "    ind = list(data.index)\n",
    "    scaler = MinMaxScaler(feature_range=feat_range)\n",
    "    scaler.fit(data)\n",
    "    df = pd.DataFrame(data=scaler.transform(data), index=ind, columns=cols)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_k_chi2(X, y, k=1):\n",
    "    \"\"\"\n",
    "    Purpose\n",
    "    -------\n",
    "    Select K best features using Chi squared test.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    X: Features in a Pandas dataframe.\n",
    "    y: Targets in a Pandas dataframe.\n",
    "    k: Value for k-best feature estimation.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A Pandas dataframe with the k-best features.\n",
    "    \"\"\"\n",
    "    \n",
    "    selector = SelectKBest(chi2, k=k).fit(X, y)\n",
    "    mask = selector.get_support()\n",
    "    new_features = X.columns[mask]\n",
    "    \n",
    "    return X[new_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original dataset with all the features calculated in feature-calculation-mordred notebook.\n",
    "df = pd.read_csv('../data/bitter_sweet_2d_plus_3d_descriptors.tsv.gz', compression='gzip', sep=\"\\t\", index_col=0, dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into feature and target dataframes.\n",
    "X = df[columns[3:-1]]\n",
    "X = X.apply(pd.to_numeric, errors='coerce') # Change numbers as strings to numeric \n",
    "                                            # and relpace strings with NaNs.\n",
    "#X = X.astype(dtype='float64') # Convert dtypes to float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['nAcid'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['SMR_VSA2'] = X['SMR_VSA2'].astype(dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.loc[:,columns[-1:]]\n",
    "y.Target.replace(to_replace='Sweet', value=1, inplace=True) # Replace 'Sweet' label with 1.\n",
    "y.Target.replace(to_replace='Bitter', value=0, inplace=True) # Replace 'Bitter' label with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features:  2163\n",
      "Total number of samples:  4742\n",
      "To check if there are any null values in the features and how many:  True 3325048\n",
      "To check if there are any null values in the target and how many: False 0\n",
      "The total number of Sweet targets:  2741\n",
      "The total number of Bitter targets:  2001\n"
     ]
    }
   ],
   "source": [
    "# Print some metrics about the data.\n",
    "print \"Total number of features: \", X.shape[1] \n",
    "print \"Total number of samples: \", X.shape[0]\n",
    "print \"To check if there are any null values in the features and how many: \", \\\n",
    "       X.isnull().values.any(), X.isnull().sum().sum() \n",
    "print \"To check if there are any null values in the target and how many:\", \\\n",
    "       y.isnull().values.any(), y.isnull().sum().sum() \n",
    "print \"The total number of Sweet targets: \", y[y.Target == 1].count()[0]\n",
    "print \"The total number of Bitter targets: \", y[y.Target == 0].count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaNs with the column mean. Keep columns with atleast 80% non NaNs. \n",
    "# Remove columns with only NaN values.\n",
    "X_no_nan = nan_filter(data=X, thresh=80, value='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To check if there are any null values in the features after fixing nans and how many:  False 0\n",
      "Total number of features left after fixing NaNs:  1552\n"
     ]
    }
   ],
   "source": [
    "print \"To check if there are any null values in the features after fixing nans and how many: \", \\\n",
    "       X_no_nan.isnull().values.any(), X_no_nan.isnull().sum().sum() \n",
    "print \"Total number of features left after fixing NaNs: \", X_no_nan.shape[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABCGG</th>\n",
       "      <th>nAcid</th>\n",
       "      <th>nBase</th>\n",
       "      <th>SpAbs_A</th>\n",
       "      <th>SpMax_A</th>\n",
       "      <th>SpDiam_A</th>\n",
       "      <th>SpAD_A</th>\n",
       "      <th>SpMAD_A</th>\n",
       "      <th>LogEE_A</th>\n",
       "      <th>...</th>\n",
       "      <th>SRW10</th>\n",
       "      <th>TSRW10</th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>WPath</th>\n",
       "      <th>WPol</th>\n",
       "      <th>Zagreb1</th>\n",
       "      <th>Zagreb2</th>\n",
       "      <th>mZagreb1</th>\n",
       "      <th>mZagreb2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.213262</td>\n",
       "      <td>16.059815</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.766735</td>\n",
       "      <td>2.52242</td>\n",
       "      <td>4.95823</td>\n",
       "      <td>28.766735</td>\n",
       "      <td>1.250728</td>\n",
       "      <td>4.052767</td>\n",
       "      <td>...</td>\n",
       "      <td>10.247042</td>\n",
       "      <td>72.317821</td>\n",
       "      <td>342.116212</td>\n",
       "      <td>7.602582</td>\n",
       "      <td>1110</td>\n",
       "      <td>43</td>\n",
       "      <td>120.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>10.451389</td>\n",
       "      <td>5.291667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1552 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ABC      ABCGG  nAcid  nBase    SpAbs_A  SpMax_A  SpDiam_A  \\\n",
       "0  17.213262  16.059815      0      0  28.766735  2.52242   4.95823   \n",
       "\n",
       "      SpAD_A   SpMAD_A   LogEE_A    ...         SRW10     TSRW10          MW  \\\n",
       "0  28.766735  1.250728  4.052767    ...     10.247042  72.317821  342.116212   \n",
       "\n",
       "        AMW  WPath  WPol  Zagreb1  Zagreb2   mZagreb1  mZagreb2  \n",
       "0  7.602582   1110    43    120.0    147.0  10.451389  5.291667  \n",
       "\n",
       "[1 rows x 1552 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_no_nan.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise and save all features without any selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_nan_norm = normalize_mm(X_no_nan)\n",
    "X_ =  pd.concat([X_no_nan_norm,y], axis=1)\n",
    "X_.to_pickle('../data/X_all.pkl', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of features are still quite high. It might be reasonable to find the most important features in order to keep the feature:data points ratio to 1:10. There are multiple methods that we can use to do feature selection and here I am going to try a few from the sklearn.feature_selection module (http://scikit-learn.org/stable/modules/feature_selection.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing features with low variance\n",
    "Remove all features whose variance doesn’t meet some threshold for example remove all zero-variance features, i.e. features that have the same value in all samples.\n",
    "\n",
    "I would try both remove all zero-variance features and all features that are either one or zero (on or off) in more than 80% of the samples respectively. Boolean features are Bernoulli random variables, and the variance of such variables is given by\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n",
    "  <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "    <mi mathvariant=\"normal\">V</mi>\n",
    "    <mi mathvariant=\"normal\">a</mi>\n",
    "    <mi mathvariant=\"normal\">r</mi>\n",
    "  </mrow>\n",
    "  <mo stretchy=\"false\">[</mo>\n",
    "  <mi>X</mi>\n",
    "  <mo stretchy=\"false\">]</mo>\n",
    "  <mo>=</mo>\n",
    "  <mi>p</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <mn>1</mn>\n",
    "  <mo>&#x2212;<!-- − --></mo>\n",
    "  <mi>p</mi>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "</math>\n",
    "\n",
    "so we can select using the threshold .8 * (1 - .8):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features after feature selection by removing zero variace columns: 1394\n"
     ]
    }
   ],
   "source": [
    "X_zero_var = variance_thresh(data=X_no_nan, thresh=0.0)\n",
    "print \"Features after feature selection by removing zero variace columns:\", X_zero_var.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features after feature selection by removing columns that are either zero or one in more than 80% of the samples: 851\n"
     ]
    }
   ],
   "source": [
    "thresh = (.8 * (1 - .8))\n",
    "X_80 = variance_thresh(data=X_zero_var, thresh=thresh)\n",
    "print \"Features after feature selection by removing columns that are either zero or one in more than 80% of the samples:\", \\\n",
    "       X_80.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 400 features according to variance.\n",
    "df_var = X_80.var(axis=0)\n",
    "df_sorted = df_var.sort_values(axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last')\n",
    "X_var_400 = X_80[df_sorted.index[:400]]\n",
    "X_var_400 = normalize_mm(X_var_400) # Normalize before saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine target and top 400 features based on variance.\n",
    "X_var_400_ =  pd.concat([X_var_400,y], axis=1)\n",
    "X_var_400_.to_pickle('../data/X_var_400.pkl', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate feature selection\n",
    "### SelectKBest: Removes all but the highest scoring features.\n",
    "\n",
    "1. Reduce X_no_nan features to 400."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectKBest Chi2 can't take negative values hence normalize the values in the range 0 and 1.\n",
    "X_no_nan_norm = normalize_mm(X_no_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_k_400 = select_k_chi2(X_no_nan_norm, y, k=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine target and top 400 features based on Chi2 test.\n",
    "X_k_400_ = pd.concat([X_k_400, y], axis=1)\n",
    "X_k_400_.to_pickle('../data/X_k_400.pkl', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
